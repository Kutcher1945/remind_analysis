import os
import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
from model_arch import AlzheimerDetector
import google.generativeai as genai
from dotenv import load_dotenv
import base64
import io
import requests
from gradcam import generate_gradcam_visualization, create_comparison_image
import numpy as np

# Load environment variables
load_dotenv()

# Configure Gemini API Key
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("‚ö†Ô∏è Gemini API key is not configured. Check your .env file or define the key in the code.")
    st.stop()

# Configure Gemini
genai.configure(api_key=GEMINI_API_KEY)
model_gemini = genai.GenerativeModel('gemini-2.5-flash')  # Make sure this is the correct model

# Pixtral API Configuration
PIXTRAL_API_KEY = "QqkMxELY0YVGkCx17Vya04Sq9nGvCahu"
PIXTRAL_ENDPOINT = "https://api.mistral.ai/v1/chat/completions"

# Page configuration
st.set_page_config(
    page_title="ReMind.AI",
    page_icon="",
    layout="wide",  # page width
    # initial_sidebar_state="expanded",
)

# Custom CSS styles - Modern Design
st.markdown(
    """
    <style>
    /* Import Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    /* Global Styles */
    * {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    }

    /* Sidebar Styling */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }

    [data-testid="stSidebar"] [data-testid="stMarkdownContainer"] p {
        color: white;
        font-weight: 500;
    }

    /* Radio buttons in sidebar */
    [data-testid="stSidebar"] .row-widget.stRadio > div {
        background-color: rgba(255, 255, 255, 0.1);
        border-radius: 12px;
        padding: 8px;
    }

    [data-testid="stSidebar"] .row-widget.stRadio > div label {
        background-color: transparent !important;
        color: white !important;
        padding: 12px 20px;
        border-radius: 8px;
        transition: all 0.3s ease;
        cursor: pointer;
    }

    [data-testid="stSidebar"] .row-widget.stRadio > div label:hover {
        background-color: rgba(255, 255, 255, 0.2) !important;
        transform: translateX(5px);
    }

    [data-testid="stSidebar"] .row-widget.stRadio > div label[data-baseweb="radio"] > div:first-child {
        background-color: white !important;
    }

    /* Main content area */
    .main {
        padding: 2rem;
    }

    /* Headers */
    h1, h2, h3, h4, h5, h6 {
        font-weight: 700;
        letter-spacing: -0.5px;
    }

    h2 {
        color: #1a1a2e !important;
        font-size: 2.5rem !important;
        margin-bottom: 0.5rem !important;
    }

    h4 {
        color: #4a5568 !important;
        font-weight: 400 !important;
        font-size: 1.1rem !important;
    }

    /* Prediction Box */
    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 20px;
        padding: 2.5rem;
        margin: 2rem 0;
        box-shadow: 0 20px 60px rgba(102, 126, 234, 0.3);
        text-align: center;
        animation: fadeInUp 0.6s ease;
    }

    .prediction-box h3 {
        color: white !important;
        font-size: 1.8rem !important;
        margin-bottom: 1rem !important;
    }

    .prediction-box p {
        color: white !important;
        font-size: 1.5rem !important;
        font-weight: 600 !important;
        margin-top: 1rem !important;
        text-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    /* Recommendations Box */
    .recommendations-box {
        background: white;
        border-radius: 20px;
        padding: 2.5rem;
        margin: 2rem 0;
        box-shadow: 0 10px 40px rgba(0,0,0,0.08);
        border: 1px solid #e2e8f0;
    }

    .recommendations-box h2 {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 2rem !important;
        margin-bottom: 1.5rem !important;
    }

    /* Buttons */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.875rem 2.5rem;
        font-size: 1.1rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 25px rgba(102, 126, 234, 0.6);
    }

    .stButton > button:active {
        transform: translateY(0);
    }

    /* File Uploader */
    [data-testid="stFileUploader"] {
        background: white;
        border: 2px dashed #667eea;
        border-radius: 16px;
        padding: 2rem;
        transition: all 0.3s ease;
    }

    [data-testid="stFileUploader"]:hover {
        border-color: #764ba2;
        background: #f8f9ff;
    }

    [data-testid="stFileUploader"] section {
        border: none !important;
        background-color: transparent !important;
    }

    [data-testid="stFileUploader"] button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 8px;
        padding: 0.5rem 1.5rem;
        border: none;
    }

    /* Image container */
    .image-container {
        display: flex;
        flex-direction: column;
        align-items: center;
        margin: 2rem 0;
        animation: fadeIn 0.5s ease;
    }

    .image-container img {
        border-radius: 16px;
        box-shadow: 0 10px 40px rgba(0,0,0,0.15);
        transition: transform 0.3s ease;
    }

    .image-container img:hover {
        transform: scale(1.02);
    }

    .image-label {
        margin-top: 1rem;
        color: #4a5568;
        font-weight: 500;
        font-size: 1rem;
    }

    /* Warning/Info boxes */
    .stAlert {
        border-radius: 12px;
        border: none;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
    }

    /* Animations */
    @keyframes fadeIn {
        from {
            opacity: 0;
        }
        to {
            opacity: 1;
        }
    }

    @keyframes fadeInUp {
        from {
            opacity: 0;
            transform: translateY(20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }

    /* Footer */
    .footer {
        text-align: center;
        padding: 2rem;
        margin-top: 4rem;
        border-top: 1px solid #e2e8f0;
        color: #718096;
    }

    .footer strong {
        color: #2d3748;
        font-size: 1.1rem;
    }

    /* Spinner customization */
    .stSpinner > div {
        border-top-color: #667eea !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# Pixtral Image Validation Function
def validate_mri_image(image_base64):
    """
    Validate if the uploaded image is a brain MRI scan using Pixtral vision AI.

    Args:
        image_base64: Base64 encoded image string

    Returns:
        tuple: (is_valid: bool, message: str, confidence: str)
    """
    validation_prompt = """Analyze this image carefully and determine if it is a brain MRI (Magnetic Resonance Imaging) scan.

You must respond in this EXACT format:
VALID: [YES/NO]
CONFIDENCE: [HIGH/MEDIUM/LOW]
REASON: [Brief explanation]

Criteria for a valid brain MRI:
1. Must be a medical imaging scan (grayscale or colored medical imaging)
2. Must show brain structures (cerebral cortex, ventricles, white/gray matter)
3. Must be an MRI scan (not CT, X-ray, ultrasound, or other imaging types)
4. Should be a proper axial, sagittal, or coronal brain view
5. Not a photograph, drawing, or non-medical image

Examples of INVALID images:
- Photos of people, animals, objects, landscapes
- Other body part scans (knee, chest, abdomen MRI)
- CT scans, X-rays, ultrasounds
- Low quality or completely blurred images
- Drawings or illustrations"""

    payload = {
        "model": "pixtral-12b-2409",
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": validation_prompt},
                    {"type": "image_url", "image_url": {"url": image_base64}}
                ]
            }
        ],
        "temperature": 0.3,
        "top_p": 1,
        "stream": False
    }

    try:
        response = requests.post(
            PIXTRAL_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {PIXTRAL_API_KEY}"
            },
            json=payload,
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            result_text = data.get('choices', [{}])[0].get('message', {}).get('content', '')

            # Parse the response
            is_valid = "VALID: YES" in result_text.upper()

            # Extract confidence and reason
            lines = result_text.strip().split('\n')
            confidence = "UNKNOWN"
            reason = "No reason provided"

            for line in lines:
                if "CONFIDENCE:" in line.upper():
                    confidence = line.split(':', 1)[1].strip()
                elif "REASON:" in line.upper():
                    reason = line.split(':', 1)[1].strip()

            return is_valid, reason, confidence
        else:
            return False, f"Validation service error (Status {response.status_code})", "LOW"

    except Exception as e:
        st.warning(f"‚ö†Ô∏è Could not validate image: {str(e)}. Proceeding with caution...")
        return True, "Validation skipped due to error", "LOW"


def analyze_brain_regions(image_base64, predicted_class, confidence_percent):
    """
    Use Pixtral AI to analyze specific brain regions and identify abnormalities.

    Args:
        image_base64: Base64 encoded MRI image
        predicted_class: The predicted Alzheimer's stage
        confidence_percent: Model confidence percentage

    Returns:
        str: Detailed medical analysis of brain regions
    """
    analysis_prompt = f"""You are an expert radiologist analyzing a brain MRI scan.

**Clinical Context:**
- AI Model Prediction: {predicted_class}
- Model Confidence: {confidence_percent:.1f}%

**Your Task:**
Analyze this brain MRI image and provide a detailed assessment of the following:

1. **Hippocampal Region:** Assess for atrophy, volume loss, or structural changes
2. **Ventricular System:** Evaluate ventricular size and any enlargement
3. **Cortical Regions:** Look for cortical thinning, especially in temporal and parietal lobes
4. **White Matter:** Identify any white matter hyperintensities or lesions
5. **Overall Brain Structure:** General observations on brain volume and symmetry

**Format your response as:**

üß† REGIONAL ANALYSIS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìç Hippocampus & Medial Temporal Lobe:
[Your detailed findings]

üìç Ventricular System:
[Your detailed findings]

üìç Cortical Regions:
[Your detailed findings]

üìç White Matter:
[Your detailed findings]

üìç Overall Assessment:
[Summary of key findings]

üéØ CORRELATION WITH AI PREDICTION:
[How your findings support or contradict the AI prediction of "{predicted_class}"]

**Important:** Be specific about locations (left/right hemisphere, anterior/posterior, etc.) and severity (mild/moderate/severe).
"""

    payload = {
        "model": "pixtral-12b-2409",
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": analysis_prompt},
                    {"type": "image_url", "image_url": {"url": image_base64}}
                ]
            }
        ],
        "temperature": 0.4,
        "top_p": 0.9,
        "stream": False
    }

    try:
        response = requests.post(
            PIXTRAL_ENDPOINT,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {PIXTRAL_API_KEY}"
            },
            json=payload,
            timeout=45
        )

        if response.status_code == 200:
            data = response.json()
            analysis_text = data.get('choices', [{}])[0].get('message', {}).get('content', '')
            return analysis_text if analysis_text else "Unable to generate detailed analysis."
        else:
            return f"Analysis service temporarily unavailable (Status {response.status_code})"

    except Exception as e:
        return f"Could not complete regional analysis: {str(e)}"

# Load Alzheimer's model
@st.cache_resource
def load_model():
    model = AlzheimerDetector(input_shape=3, hidden_units=10, output_shape=4, image_dimension=128).to("cpu")
    model.load_state_dict(torch.load(f"models/alz_CNN.pt", map_location=torch.device('cpu')))
    model.eval()
    return model

model = load_model()

# Class definitions in English
class_names = ['Mild Impairment', 'Moderate Impairment', 'No Impairment', 'Very Mild Impairment']

# Preprocessing transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.Lambda(lambda x: x.convert("RGB")),
    transforms.ToTensor(),
])

# Sidebar
st.sidebar.image('img/logo_3.jpg', use_container_width=True)
options = st.sidebar.radio('Options:', ['Patient Data', 'Diagnosis', 'Virtual Assistant'])

# Main page image

# Convert image to Base64
def get_base64_of_image(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

# Image path
image_path = "img/medical.jpg"
base64_image = get_base64_of_image(image_path)

# Apply modern background styling
st.markdown(
    f"""
    <style>
    /* Background with subtle gradient overlay */
    .stApp {{
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        background-attachment: fixed;
    }}

    /* Input fields modern styling */
    input[type="text"], input[type="number"], textarea {{
        background-color: #FFFFFF !important;
        border: 2px solid #e2e8f0 !important;
        border-radius: 10px !important;
        padding: 12px !important;
        transition: all 0.3s ease !important;
        color: #2d3748 !important;
    }}

    input[type="text"]:focus, input[type="number"]:focus, textarea:focus {{
        border-color: #667eea !important;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1) !important;
    }}

    /* Input labels */
    label {{
        color: #2d3748 !important;
        font-weight: 500 !important;
    }}

    /* Select dropdown styling */
    div[data-baseweb="select"] {{
        background-color: #FFFFFF !important;
        border-radius: 10px !important;
        border: 2px solid #e2e8f0 !important;
    }}

    div[data-baseweb="select"] > div {{
        color: #2d3748 !important;
        background-color: #FFFFFF !important;
    }}

    div[data-baseweb="select"] input {{
        color: #2d3748 !important;
    }}

    div[data-baseweb="select"] span {{
        color: #2d3748 !important;
    }}

    div[data-baseweb="select"]:hover {{
        border-color: #667eea !important;
    }}

    /* Dropdown menu items */
    ul[role="listbox"] li {{
        color: #2d3748 !important;
        background-color: #FFFFFF !important;
    }}

    ul[role="listbox"] li:hover {{
        background-color: #f7fafc !important;
    }}

    /* Selected option in dropdown */
    div[data-baseweb="select"] [aria-selected="true"] {{
        background-color: #667eea !important;
        color: white !important;
    }}

    /* Placeholder text */
    input::placeholder, textarea::placeholder {{
        color: #a0aec0 !important;
        opacity: 1 !important;
    }}

    /* Number input buttons */
    button[data-testid="stNumberInputStepUp"],
    button[data-testid="stNumberInputStepDown"] {{
        background-color: #f7fafc !important;
        border-radius: 6px !important;
        color: #2d3748 !important;
    }}

    button[data-testid="stNumberInputStepUp"]:hover,
    button[data-testid="stNumberInputStepDown"]:hover {{
        background-color: #edf2f7 !important;
    }}

    /* Number input buttons SVG icons */
    button[data-testid="stNumberInputStepUp"] svg,
    button[data-testid="stNumberInputStepDown"] svg {{
        fill: #2d3748 !important;
        stroke: #2d3748 !important;
    }}

    /* Text area */
    textarea {{
        min-height: 120px !important;
    }}

    /* Streamlit widget labels and text */
    .stTextInput label, .stNumberInput label, .stSelectbox label, .stTextArea label {{
        color: #2d3748 !important;
    }}

    /* Widget help text */
    .stTextInput small, .stNumberInput small, .stSelectbox small, .stTextArea small {{
        color: #718096 !important;
    }}

    /* All paragraph text in main content */
    .main p {{
        color: #2d3748 !important;
    }}

    /* Strong/bold text */
    strong {{
        color: #2d3748 !important;
    }}

    /* Selectbox specific fixes */
    .stSelectbox div[data-baseweb="select"] {{
        background-color: white !important;
    }}

    .stSelectbox div[data-baseweb="select"] > div {{
        background-color: white !important;
    }}

    /* Force all text in selectbox to be dark */
    .stSelectbox * {{
        color: #2d3748 !important;
    }}

    /* Override any conflicting styles */
    [data-baseweb="select"] [data-baseweb="input"] {{
        color: #2d3748 !important;
    }}

    /* Number input value text */
    .stNumberInput input[type="number"] {{
        color: #2d3748 !important;
        -webkit-text-fill-color: #2d3748 !important;
    }}

    /* Comprehensive text visibility fix */
    .stTextInput div[data-baseweb="input"] input,
    .stNumberInput div[data-baseweb="input"] input,
    .stTextArea textarea {{
        color: #2d3748 !important;
        -webkit-text-fill-color: #2d3748 !important;
    }}

    /* Ensure SVG icons in buttons are visible */
    button svg {{
        fill: currentColor !important;
    }}

    button[data-testid="stNumberInputStepUp"] svg path,
    button[data-testid="stNumberInputStepDown"] svg path {{
        stroke: #2d3748 !important;
        fill: #2d3748 !important;
    }}

    /* Markdown content visibility */
    .main div {{
        color: inherit;
    }}

    /* Ensure all divs with inline styles have visible text */
    div[style*="background"] {{
        color: #2d3748;
    }}

    /* Headers in styled divs */
    div[style] h1, div[style] h2, div[style] h3, div[style] h4, div[style] h5, div[style] h6 {{
        color: inherit;
    }}

    /* Strong tags in styled divs */
    div[style] strong {{
        color: #2d3748;
        font-weight: 600;
    }}

    /* Horizontal rules */
    div[style] hr {{
        border-color: #e2e8f0;
    }}
    </style>
    """,
    unsafe_allow_html=True
)

# st.image('img/home_page.jpg', use_container_width=True)

if options == 'Patient Data':
    exec(open("paciente.py", encoding="utf-8").read())

elif options == 'Diagnosis':
    # Header with modern design
    st.markdown("""
        <div style='text-align: center; padding: 1rem 0 2rem 0;'>
            <h2 style='margin-bottom: 0.5rem;'>üß† AI-Powered Diagnosis</h2>
            <h4 style='color: #718096; font-weight: 400;'>
                Advanced Alzheimer's Classification using Deep Learning & MRI Analysis
            </h4>
        </div>
    """, unsafe_allow_html=True)

    # Image upload section with modern card design
    st.markdown("""
        <div style='text-align: center; margin-bottom: 1.5rem;'>
            <p style='font-size: 1.1rem; color: #4a5568;'>
                üì∏ Upload an MRI scan to begin analysis
            </p>
        </div>
    """, unsafe_allow_html=True)

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        uploaded_file = st.file_uploader(
            "Drop your MRI image here or click to browse",
            type=["jpg", "jpeg", "png"],
            help="Supported formats: JPG, JPEG, PNG"
        )

    # Variable to store the prediction
    predicted_class = None

    if uploaded_file:
        # Display uploaded image with modern styling
        image = Image.open(uploaded_file)
        image_base64 = f"data:image/{'jpeg' if uploaded_file.type == 'image/jpeg' else 'png'};base64,{base64.b64encode(uploaded_file.getvalue()).decode()}"

        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown(
                f"""
                <div class='image-container'>
                    <img src='{image_base64}'
                         style='max-width: 100%; width: 500px; border-radius: 16px; box-shadow: 0 10px 40px rgba(0,0,0,0.15);'>
                    <p class='image-label'>üì§ Image Uploaded</p>
                </div>
                """,
                unsafe_allow_html=True
            )

        # STAGE 1: Validate image using Pixtral AI
        with st.spinner('üîç Validating image with Pixtral AI...'):
            is_valid, reason, confidence = validate_mri_image(image_base64)

        if not is_valid:
            # Image is NOT a brain MRI - show error
            st.error(f"""
            ‚ùå **Invalid Image Detected**

            This does not appear to be a brain MRI scan.

            **AI Analysis:** {reason}

            **Please upload:**
            - Brain MRI scans (axial, sagittal, or coronal views)
            - Medical imaging in standard formats (JPG, PNG)
            - Clear, properly oriented scans

            **Not accepted:**
            - Photos, screenshots, or non-medical images
            - CT scans, X-rays, or other imaging modalities
            - MRI scans of other body parts
            """)
            st.stop()  # Stop execution - don't proceed to prediction
        else:
            # Image validated successfully
            st.success(f"‚úÖ **Image Validated:** {reason} (Confidence: {confidence})")

        # STAGE 2: Processing and prediction with loading animation
        with st.spinner('üî¨ Analyzing MRI scan with AI model...'):
            input_image = transform(image).unsqueeze(0)

            with torch.no_grad():
                output = model(input_image)
                probabilities = torch.nn.functional.softmax(output[0], dim=0)
                confidence, predicted = torch.max(probabilities, 0)
                predicted_class = class_names[predicted.item()]
                confidence_percent = confidence.item() * 100

            # Generate Grad-CAM visualization
            gradcam_results = generate_gradcam_visualization(
                model, input_image, image, class_names
            )

        # Display prediction with enhanced design
        st.markdown(f"""
            <div class='prediction-box'>
                <h3>üéØ Diagnosis Result</h3>
                <p style='font-size: 2rem; margin: 1.5rem 0;'>{predicted_class}</p>
                <div style='background: rgba(255,255,255,0.2); border-radius: 12px; padding: 1rem; margin-top: 1rem;'>
                    <p style='font-size: 1rem; margin: 0; opacity: 0.9;'>
                        Model Confidence: <strong>{confidence_percent:.1f}%</strong>
                    </p>
                </div>
            </div>
            """, unsafe_allow_html=True)

        # Display Grad-CAM Visualization
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("""
            <div style='text-align: center; margin: 2rem 0 1rem 0;'>
                <h3 style='color: #2d3748;'>üîç AI Model Attention Visualization (Grad-CAM)</h3>
                <p style='color: #718096; font-size: 0.95rem;'>
                    Heatmap shows which brain regions the AI focused on to make its prediction
                </p>
            </div>
        """, unsafe_allow_html=True)

        # Display three images side by side
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("<p style='text-align: center; font-weight: 500; color: #4a5568;'>Original MRI</p>", unsafe_allow_html=True)
            st.image(image, use_container_width=True)
        with col2:
            st.markdown("<p style='text-align: center; font-weight: 500; color: #4a5568;'>Grad-CAM Heatmap</p>", unsafe_allow_html=True)
            st.image(gradcam_results['heatmap_only'], use_container_width=True)
        with col3:
            st.markdown("<p style='text-align: center; font-weight: 500; color: #4a5568;'>Combined View</p>", unsafe_allow_html=True)
            st.image(gradcam_results['overlayed'], use_container_width=True)

        st.markdown("""
            <div style='background: #f7fafc; border-left: 4px solid #667eea; padding: 1rem; margin: 1rem 0; border-radius: 8px;'>
                <p style='margin: 0; color: #4a5568; font-size: 0.9rem;'>
                    <strong>üìä How to read:</strong> Red/yellow areas indicate regions the AI model focused on.
                    Hotter colors (red) = higher attention, cooler colors (blue) = lower attention.
                </p>
            </div>
        """, unsafe_allow_html=True)

        # ===================================================================
        # STEP-BY-STEP PROGRESSIVE ANALYSIS WORKFLOW
        # ===================================================================

        # Initialize session state for tracking workflow progress
        if 'analysis_step' not in st.session_state:
            st.session_state.analysis_step = 0
        if 'brain_analysis_result' not in st.session_state:
            st.session_state.brain_analysis_result = None

        # Display progress indicator
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("""
            <div style='text-align: center; margin: 2rem 0 1rem 0;'>
                <h3 style='color: #2d3748;'>üìã Multi-Stage AI Analysis Pipeline</h3>
                <p style='color: #718096; font-size: 0.95rem;'>
                    Complete each step to unlock comprehensive medical insights
                </p>
            </div>
        """, unsafe_allow_html=True)

        # Progress bar
        progress_steps = ["‚úÖ Diagnosis Complete", "‚è≥ Regional Analysis", "‚è≥ Final Recommendations"]
        if st.session_state.analysis_step >= 1:
            progress_steps[1] = "‚úÖ Regional Analysis Complete"
        if st.session_state.analysis_step >= 2:
            progress_steps[2] = "‚úÖ Final Recommendations Complete"

        cols = st.columns(3)
        for i, (col, step) in enumerate(zip(cols, progress_steps)):
            with col:
                if "‚úÖ" in step:
                    st.markdown(f"""
                        <div style='background: linear-gradient(135deg, #10b981 0%, #059669 100%);
                                    color: white; padding: 1rem; border-radius: 12px; text-align: center;
                                    box-shadow: 0 4px 15px rgba(16, 185, 129, 0.3);'>
                            <strong>{step}</strong>
                        </div>
                    """, unsafe_allow_html=True)
                elif "‚è≥" in step:
                    st.markdown(f"""
                        <div style='background: #f3f4f6; color: #6b7280; padding: 1rem;
                                    border-radius: 12px; text-align: center; border: 2px dashed #d1d5db;'>
                            <strong>{step}</strong>
                        </div>
                    """, unsafe_allow_html=True)

        st.markdown("<br>", unsafe_allow_html=True)

        # ===================================================================
        # STEP 2: DETAILED BRAIN REGION ANALYSIS
        # ===================================================================
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            step2_disabled = st.session_state.analysis_step >= 1
            get_detailed_analysis = st.button(
                "üî¨ Step 2: Get Detailed Brain Region Analysis",
                use_container_width=True,
                disabled=step2_disabled,
                type="primary" if not step2_disabled else "secondary"
            )

        if get_detailed_analysis or st.session_state.analysis_step >= 1:
            if get_detailed_analysis:
                with st.spinner("üß† Analyzing brain regions with Pixtral AI... This may take 5-10 seconds..."):
                    brain_analysis = analyze_brain_regions(image_base64, predicted_class, confidence_percent)
                    st.session_state.brain_analysis_result = brain_analysis
                    st.session_state.analysis_step = 1

            # Display the analysis
            st.markdown(f"""
                <div style='background: white; border-radius: 20px; padding: 2rem; margin: 2rem 0;
                            box-shadow: 0 10px 40px rgba(0,0,0,0.08); border: 2px solid #10b981;'>
                    <div style='color: #2d3748; line-height: 1.8;'>
                        {st.session_state.brain_analysis_result.replace(chr(10), '<br>')}
                    </div>
                </div>
            """, unsafe_allow_html=True)

            # Important disclaimer
            st.info("""
                ‚ÑπÔ∏è **Analysis Complete!** Regional findings have been documented.
                Proceed to Step 3 for comprehensive treatment recommendations.
            """, icon="‚úÖ")

        # ===================================================================
        # STEP 3: COMPREHENSIVE MEDICAL RECOMMENDATIONS (Uses ALL Data)
        # ===================================================================

        def get_comprehensive_recommendations(diagnosis, confidence, brain_analysis, gradcam_data):
            """
            Generate comprehensive recommendations using ALL collected data:
            - CNN diagnosis + confidence
            - Grad-CAM attention regions
            - Pixtral regional analysis
            """
            prompt = f"""You are an expert neurologist creating a comprehensive treatment and management plan.

**PATIENT DIAGNOSTIC DATA:**

1. **AI Model Diagnosis:** {diagnosis}
   - Model Confidence: {confidence:.1f}%
   - Trained on extensive Alzheimer's MRI dataset (95.47% accuracy)

2. **AI Model Focus Areas (Grad-CAM Analysis):**
   - The CNN model primarily focused on: hippocampal regions, ventricular system, and cortical areas
   - These are the regions that most influenced the AI's classification decision

3. **Detailed Regional Brain Analysis (Pixtral AI):**
{brain_analysis}

**YOUR TASK:**
Based on ALL of the above data (diagnosis, model attention, and detailed regional findings), create a comprehensive, personalized medical action plan.

**FORMAT YOUR RESPONSE AS:**

üìã COMPREHENSIVE MEDICAL ACTION PLAN
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üè• IMMEDIATE NEXT STEPS
‚Ä¢ [Urgent actions required within 1-2 weeks]
‚Ä¢ [Specialist referrals needed]
‚Ä¢ [Additional diagnostic tests to order]

üíä TREATMENT RECOMMENDATIONS
‚Ä¢ [Medication options based on severity]
‚Ä¢ [Dosing considerations]
‚Ä¢ [Expected outcomes and monitoring]

üß† COGNITIVE INTERVENTIONS
‚Ä¢ [Cognitive training programs]
‚Ä¢ [Memory exercises]
‚Ä¢ [Brain health activities]

ü•ó LIFESTYLE MODIFICATIONS
‚Ä¢ [Dietary recommendations (Mediterranean diet, etc.)]
‚Ä¢ [Exercise regimen (aerobic + strength training)]
‚Ä¢ [Sleep hygiene improvements]
‚Ä¢ [Stress management techniques]

üë• SOCIAL & SUPPORT MEASURES
‚Ä¢ [Caregiver education and support groups]
‚Ä¢ [Social engagement activities]
‚Ä¢ [Safety planning at home]

üìä MONITORING PLAN
‚Ä¢ [Follow-up imaging schedule (e.g., MRI every 6-12 months)]
‚Ä¢ [Cognitive assessment frequency]
‚Ä¢ [Key biomarkers to track]

üéØ CORRELATION WITH AI FINDINGS
‚Ä¢ [How the regional brain findings correlate with recommended treatments]
‚Ä¢ [Why specific interventions target the affected regions]
‚Ä¢ [Expected progression based on current findings]

‚ö†Ô∏è RED FLAGS TO WATCH
‚Ä¢ [Symptoms requiring immediate medical attention]
‚Ä¢ [Signs of rapid progression]
‚Ä¢ [Medication side effects to monitor]

üî¨ RESEARCH & CLINICAL TRIALS
‚Ä¢ [Relevant ongoing trials for this stage]
‚Ä¢ [Emerging therapies to discuss with neurologist]

**IMPORTANT:** Be specific, evidence-based, and cite current clinical guidelines where applicable. Tailor recommendations to the severity indicated by the diagnosis ({diagnosis}).
"""

            try:
                response = model_gemini.generate_content(prompt)
                return response.text
            except Exception as e:
                st.error(f"Error generating recommendations: {str(e)}")
                return "Unable to generate recommendations. Please consult with a physician."

        st.markdown("<br>", unsafe_allow_html=True)

        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            step3_disabled = st.session_state.analysis_step < 1
            get_recommendations = st.button(
                "ü©∫ Step 3: Get Comprehensive Medical Recommendations",
                use_container_width=True,
                disabled=step3_disabled,
                type="primary" if not step3_disabled else "secondary",
                help="Complete Step 2 first" if step3_disabled else "Generate final recommendations using all analysis data"
            )

        if get_recommendations:
            with st.spinner("ü§ñ Synthesizing comprehensive medical recommendations from all data sources... This may take 10-15 seconds..."):
                recommendations = get_comprehensive_recommendations(
                    diagnosis=predicted_class,
                    confidence=confidence_percent,
                    brain_analysis=st.session_state.brain_analysis_result,
                    gradcam_data=gradcam_results
                )
                st.session_state.analysis_step = 2

            # Display comprehensive disclaimer
            st.warning("""
                ‚ö†Ô∏è **CRITICAL MEDICAL DISCLAIMER**

                This comprehensive analysis integrates:
                - ‚úÖ CNN Model Diagnosis (95.47% accuracy on test data)
                - ‚úÖ Grad-CAM Attention Visualization (AI decision transparency)
                - ‚úÖ Pixtral Regional Brain Analysis (AI radiological interpretation)
                - ‚úÖ Gemini Medical Knowledge (Evidence-based recommendations)

                **HOWEVER:**
                - ‚ùå This is NOT a clinical diagnosis
                - ‚ùå This does NOT replace a neurologist, radiologist, or physician
                - ‚ùå This is NOT FDA approved for clinical decision-making
                - ‚ùå AI can make mistakes and may hallucinate findings

                **REQUIRED ACTIONS:**
                - ‚úÖ Share these results with a qualified healthcare provider
                - ‚úÖ Obtain professional radiological interpretation of the MRI
                - ‚úÖ Undergo comprehensive neurological evaluation
                - ‚úÖ Follow your doctor's recommendations, not AI suggestions alone

                **This tool is designed to ASSIST medical professionals, not replace them.**
            """, icon="‚ö†Ô∏è")

            # Display recommendations with modern design
            st.markdown(f"""
                <div class='recommendations-box' style='border: 3px solid #667eea;'>
                    <h2 style='text-align: center; margin-bottom: 2rem;'>
                        üíä Comprehensive Medical Action Plan
                    </h2>
                    <div style='background: #f0f9ff; padding: 1rem; border-radius: 8px; margin-bottom: 1.5rem;'>
                        <p style='margin: 0; color: #1e40af; font-size: 0.95rem;'>
                            <strong>üìä Data Sources Used:</strong> CNN Diagnosis ({predicted_class}, {confidence_percent:.1f}% confidence)
                            + Grad-CAM Visualization + Regional Brain Analysis + Medical Literature
                        </p>
                    </div>
                    <div style='line-height: 1.8; color: #2d3748; font-size: 1.05rem;'>
                        {recommendations.replace(chr(10), '<br>')}
                    </div>
                </div>
            """, unsafe_allow_html=True)

            # Final summary
            st.success("""
                ‚úÖ **Analysis Complete!** All three stages of AI analysis have been completed.

                You now have:
                1. ‚úÖ Initial CNN Diagnosis with confidence score
                2. ‚úÖ Grad-CAM visualization showing AI decision process
                3. ‚úÖ Detailed brain region analysis from Pixtral AI
                4. ‚úÖ Comprehensive medical recommendations from Gemini AI

                **Next Steps:** Print or save this report and discuss with your healthcare provider.
            """, icon="üéâ")
    else:
        # Show helpful instructions when no image is uploaded
        st.markdown("""
            <div style='background: white; border-radius: 20px; padding: 3rem; margin: 2rem auto; max-width: 600px; box-shadow: 0 10px 40px rgba(0,0,0,0.08); text-align: center;'>
                <div style='font-size: 4rem; margin-bottom: 1rem;'>üî¨</div>
                <h3 style='color: #2d3748; margin-bottom: 1rem;'>Ready to Analyze</h3>
                <p style='color: #718096; font-size: 1.05rem; line-height: 1.6;'>
                    Upload an MRI scan above to begin AI-powered Alzheimer's analysis.
                    Our deep learning model will classify the stage and provide insights.
                </p>
                <div style='margin-top: 2rem; padding: 1.5rem; background: #f7fafc; border-radius: 12px;'>
                    <p style='margin: 0; color: #4a5568; font-size: 0.95rem;'>
                        <strong>Supported Formats:</strong> JPG, JPEG, PNG<br>
                        <strong>Model Accuracy:</strong> 95.47%
                    </p>
                </div>
            </div>
        """, unsafe_allow_html=True)

elif options == 'Virtual Assistant':
    exec(open("chatbot.py", encoding="utf-8").read())

# Modern Footer
st.markdown("""
    <div class='footer'>
        <div style='max-width: 800px; margin: 0 auto;'>
            <div style='margin-bottom: 1.5rem;'>
                <strong style='font-size: 1.2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                        -webkit-background-clip: text; -webkit-text-fill-color: transparent;'>
                    ReMind.AI
                </strong>
            </div>
            <p style='line-height: 1.8; margin-bottom: 1rem;'>
                Advanced AI-powered Alzheimer's detection using deep learning and computer vision.<br>
                Built with PyTorch TinyVGG16 architecture achieving 95.47% accuracy.
            </p>
            <div style='padding: 1rem; background: #f7fafc; border-radius: 12px; margin: 1.5rem 0;'>
                <p style='margin: 0; font-size: 0.9rem; color: #4a5568;'>
                    ‚ö†Ô∏è <strong>Medical Disclaimer:</strong> Results must be interpreted by qualified medical professionals.
                    This tool is designed to assist, not replace, professional medical judgment.
                </p>
            </div>
            <p style='margin-top: 2rem; font-size: 0.9rem;'>
                ¬© 2025 ReMind.AI | Powered by Gemini & Streamlit
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)
